{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains can be used for very basic text generation. Think about every word in a corpus as a state. We can make a simple assumption that the next word is only dependent on the previous word - which is the basic assumption of a Markov chain.\n",
    "\n",
    "Markov chains don't generate text as well as deep learning, but it's a good (and fun!) start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Text to Imitate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're specifically going to generate text in the style of Ali Wong, so as a first step, let's extract the text from her comedy routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlonsoPraisesAMR</th>\n",
       "      <td>Fernando Alonso was delighted with his drive t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HamiltonsCarIssues</th>\n",
       "      <td>Lewis Hamilton was left to rue the struggles h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeclercsPoorQualifying</th>\n",
       "      <td>Charles Leclerc enjoyed a strong drive to P4 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerezOnHisFuture</th>\n",
       "      <td>Sergio Perez expects his Red Bull and F1 futur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SainzOnHisFuture</th>\n",
       "      <td>Carlos Sainz feels that now is the time to “sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotoOnMercedes</th>\n",
       "      <td>Toto Wolff has admitted that Mercedes are in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TsunodaPoints</th>\n",
       "      <td>Yuki Tsunoda was full of relief after scoring ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               transcript\n",
       "AlonsoPraisesAMR        Fernando Alonso was delighted with his drive t...\n",
       "HamiltonsCarIssues      Lewis Hamilton was left to rue the struggles h...\n",
       "LeclercsPoorQualifying  Charles Leclerc enjoyed a strong drive to P4 i...\n",
       "PerezOnHisFuture        Sergio Perez expects his Red Bull and F1 futur...\n",
       "SainzOnHisFuture        Carlos Sainz feels that now is the time to “sp...\n",
       "TotoOnMercedes          Toto Wolff has admitted that Mercedes are in a...\n",
       "TsunodaPoints           Yuki Tsunoda was full of relief after scoring ..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the corpus, including punctuation!\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('corpus.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sergio Perez expects his Red Bull and F1 future to be clarified within the next month, with the Mexican out of contract next year. The Mexican has been in this exact position before – originally signi'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only PerezOnHisFuture's text\n",
    "perez_text = data.transcript.loc['PerezOnHisFuture']\n",
    "perez_text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Markov Chain Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a simple Markov chain function that creates a dictionary:\n",
    "* The keys should be all of the words in the corpus\n",
    "* The values should be a list of the words that follow the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def markov_chain(text):\n",
    "    '''The input is a string of text and the output will be a dictionary with each word as\n",
    "       a key and each value as the list of words that come after the key in the text.'''\n",
    "    \n",
    "    # Tokenize the text by word, though including punctuation\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    # Initialize a default dictionary to hold all of the words and next words\n",
    "    m_dict = defaultdict(list)\n",
    "    \n",
    "    # Create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "    for current_word, next_word in zip(words[0:-1], words[1:]):\n",
    "        m_dict[current_word].append(next_word)\n",
    "\n",
    "    # Convert the default dict back into a dictionary\n",
    "    m_dict = dict(m_dict)\n",
    "    return m_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sergio': ['Perez'],\n",
       " 'Perez': ['expects',\n",
       "  'is',\n",
       "  'signed',\n",
       "  'still',\n",
       "  'is',\n",
       "  'says',\n",
       "  'has',\n",
       "  'hails',\n",
       "  'very'],\n",
       " 'expects': ['his'],\n",
       " 'his': ['Red',\n",
       "  'contract.',\n",
       "  'drive',\n",
       "  'future.',\n",
       "  'F1',\n",
       "  'ambition',\n",
       "  'career',\n",
       "  'performances',\n",
       "  'future',\n",
       "  'opening',\n",
       "  'F1',\n",
       "  'team'],\n",
       " 'Red': ['Bull',\n",
       "  'Bull',\n",
       "  'Bull',\n",
       "  'Bull',\n",
       "  'Bull',\n",
       "  'Bull,',\n",
       "  'Bull',\n",
       "  'Bull,',\n",
       "  'Bull',\n",
       "  'Bull'],\n",
       " 'Bull': ['and', 'for', 'retained', 'had', 'family', 'in', 'family.', 'seat'],\n",
       " 'and': ['F1',\n",
       "  'not',\n",
       "  'get',\n",
       "  'making',\n",
       "  'a',\n",
       "  'Fernando',\n",
       "  'Perez’s',\n",
       "  'now',\n",
       "  'is',\n",
       "  'whatever',\n",
       "  'the',\n",
       "  'not'],\n",
       " 'F1': ['future', 'future', 'after', 'and', 'career'],\n",
       " 'future': ['to', 'in', 'at', 'holds.'],\n",
       " 'to': ['be',\n",
       "  'extend',\n",
       "  'see',\n",
       "  'finish',\n",
       "  'go',\n",
       "  'P2',\n",
       "  'be',\n",
       "  'really',\n",
       "  'Ferrari',\n",
       "  'pretty',\n",
       "  'secure',\n",
       "  'lose”',\n",
       "  'team',\n",
       "  'stay'],\n",
       " 'be': ['clarified', 'long', 'a', 'a'],\n",
       " 'clarified': ['within'],\n",
       " 'within': ['the', 'a'],\n",
       " 'the': ['next',\n",
       "  'Mexican',\n",
       "  'right',\n",
       "  'even',\n",
       "  'next',\n",
       "  'Milton',\n",
       "  'case',\n",
       "  'Mexican',\n",
       "  'juggernaut',\n",
       "  'RB19,',\n",
       "  'championship',\n",
       "  'first',\n",
       "  'drivers’.',\n",
       "  'Red',\n",
       "  'wings',\n",
       "  'Mexican',\n",
       "  'talking',\n",
       "  'opening',\n",
       "  'drivers’',\n",
       "  'race',\n",
       "  'sport',\n",
       "  'driver',\n",
       "  'next',\n",
       "  'season',\n",
       "  'driver',\n",
       "  'first',\n",
       "  'season',\n",
       "  'summer',\n",
       "  'market',\n",
       "  'equation.',\n",
       "  'Spaniard',\n",
       "  'Red',\n",
       "  'paddock',\n",
       "  'Red'],\n",
       " 'next': ['month,', 'year.', 'season', 'few', 'year.”', 'year.'],\n",
       " 'month,': ['with'],\n",
       " 'with': ['the', 'Red', 'Racing', 'the', 'qualifying', 'a', 'what', 'Perez'],\n",
       " 'Mexican': ['out', 'has', 'for', 'has'],\n",
       " 'out': ['of'],\n",
       " 'of': ['contract',\n",
       "  'losing',\n",
       "  'his',\n",
       "  'chatter',\n",
       "  'late.',\n",
       "  'time,',\n",
       "  'movement',\n",
       "  'the',\n",
       "  'the',\n",
       "  'a',\n",
       "  'drivers',\n",
       "  'the'],\n",
       " 'contract': ['next', 'with'],\n",
       " 'year.': ['The'],\n",
       " 'The': ['Mexican', 'Spaniard'],\n",
       " 'has': ['been',\n",
       "  'performed',\n",
       "  'Carlos',\n",
       "  'been',\n",
       "  'let',\n",
       "  'three',\n",
       "  'three',\n",
       "  'admitted'],\n",
       " 'been': ['in', 'in', 'plenty', 'better’'],\n",
       " 'in': ['this',\n",
       "  'the',\n",
       "  '2020',\n",
       "  '2024',\n",
       "  '2022,',\n",
       "  'Formula',\n",
       "  'the',\n",
       "  'the',\n",
       "  'the',\n",
       "  '2024',\n",
       "  'the',\n",
       "  'a',\n",
       "  'the',\n",
       "  'particular',\n",
       "  'the',\n",
       "  'Japan.',\n",
       "  'F1',\n",
       "  'the',\n",
       "  'the',\n",
       "  'announcements',\n",
       "  'August.',\n",
       "  'Japan',\n",
       "  'the',\n",
       "  'Formula'],\n",
       " 'this': ['exact', 'year,'],\n",
       " 'exact': ['position'],\n",
       " 'position': ['before', 'of'],\n",
       " 'before': ['–', 'it', 'culminating'],\n",
       " '–': ['originally', 'but', 'the'],\n",
       " 'originally': ['signing'],\n",
       " 'signing': ['a'],\n",
       " 'a': ['one-year',\n",
       "  'seat',\n",
       "  'relaxed',\n",
       "  'point',\n",
       "  'two-year',\n",
       "  'difficult',\n",
       "  'Red',\n",
       "  'drivers’',\n",
       "  'fifth-place',\n",
       "  'matter',\n",
       "  'lot',\n",
       "  'month',\n",
       "  'much',\n",
       "  'coveted',\n",
       "  'number',\n",
       "  'drive',\n",
       "  'driver'],\n",
       " 'one-year': ['deal'],\n",
       " 'deal': ['with'],\n",
       " 'for': ['2021,',\n",
       "  'the',\n",
       "  'both',\n",
       "  '2024',\n",
       "  'his',\n",
       "  '2025,',\n",
       "  'sure,',\n",
       "  '2025',\n",
       "  '2025.',\n",
       "  'now,'],\n",
       " '2021,': ['so'],\n",
       " 'so': ['spending', 'far,', 'far.', 'I'],\n",
       " 'spending': ['that'],\n",
       " 'that': ['season', 'was', 'has'],\n",
       " 'season': ['earning', '–', '', 'before'],\n",
       " 'earning': ['the'],\n",
       " 'right': ['to'],\n",
       " 'extend': ['his'],\n",
       " 'contract.': [\"He's\"],\n",
       " \"He's\": ['also'],\n",
       " 'also': ['been', 'unleashed'],\n",
       " 'even': ['worse'],\n",
       " 'worse': ['position'],\n",
       " 'losing': ['his'],\n",
       " 'drive': ['with', 'for'],\n",
       " 'Racing': ['Point'],\n",
       " 'Point': ['late'],\n",
       " 'late': ['on'],\n",
       " 'on': ['in', 'home'],\n",
       " '2020': ['and'],\n",
       " 'not': ['knowing', 'only'],\n",
       " 'knowing': ['if'],\n",
       " 'if': [\"he'd\"],\n",
       " \"he'd\": ['have'],\n",
       " 'have': ['a', 'been'],\n",
       " 'seat': ['for', 'at', 'is'],\n",
       " 'but': ['given', 'as', 'also'],\n",
       " 'given': ['how'],\n",
       " 'how': ['well'],\n",
       " 'well': ['he'],\n",
       " 'he': ['has', 'nets', 'says', 'told', 'seeks'],\n",
       " 'performed': ['in'],\n",
       " '2024': ['so', 'despite', 'With'],\n",
       " 'far,': ['it’s'],\n",
       " 'it’s': ['easy'],\n",
       " 'easy': ['to'],\n",
       " 'see': ['why'],\n",
       " 'why': ['Perez'],\n",
       " 'is': ['cutting',\n",
       "  'always',\n",
       "  'once',\n",
       "  'back',\n",
       "  'revealed',\n",
       "  'in',\n",
       "  'moving',\n",
       "  'one',\n",
       "  '“Perez’s'],\n",
       " 'cutting': ['a'],\n",
       " 'relaxed': ['figure', 'about'],\n",
       " 'figure': ['when'],\n",
       " 'when': ['asked'],\n",
       " 'asked': ['about'],\n",
       " 'about': ['his', 'potential', 'it,”'],\n",
       " 'future.': ['READ'],\n",
       " 'READ': ['MORE:', 'MORE:', 'MORE:'],\n",
       " 'MORE:': ['‘Relieved’', 'Verstappen', 'Perez'],\n",
       " '‘Relieved’': ['Tsunoda'],\n",
       " 'Tsunoda': ['hails'],\n",
       " 'hails': [\"'insane'\", '‘good'],\n",
       " \"'insane'\": ['RB'],\n",
       " 'RB': ['pit', 'and'],\n",
       " 'pit': ['stop'],\n",
       " 'stop': ['as'],\n",
       " 'as': ['he', 'is', 'free', 'he', 'part', 'he'],\n",
       " 'nets': ['a'],\n",
       " 'point': ['on'],\n",
       " 'home': ['soil'],\n",
       " 'soil': ['Perez'],\n",
       " 'signed': ['a'],\n",
       " 'two-year': ['contract'],\n",
       " 'Milton': ['Keynes'],\n",
       " 'Keynes': ['team'],\n",
       " 'team': ['back', 'are', 'boss'],\n",
       " 'back': ['in', 'in', 'up'],\n",
       " '2022,': ['but'],\n",
       " 'always': ['the'],\n",
       " 'case': ['in'],\n",
       " 'Formula': ['1,', '1'],\n",
       " '1,': ['there'],\n",
       " 'there': ['were', 'has'],\n",
       " 'were': ['performance'],\n",
       " 'performance': ['clauses'],\n",
       " 'clauses': ['and'],\n",
       " 'get': ['outs'],\n",
       " 'outs': ['for'],\n",
       " 'both': ['sides.'],\n",
       " 'sides.': ['As'],\n",
       " 'As': ['it'],\n",
       " 'it': ['was,', 'won’t', 'is', 'will'],\n",
       " 'was,': ['Red'],\n",
       " 'retained': ['the'],\n",
       " 'despite': ['a'],\n",
       " 'difficult': ['campaign'],\n",
       " 'campaign': ['last'],\n",
       " 'last': ['season,', 'year'],\n",
       " 'season,': ['with'],\n",
       " 'qualifying': ['often'],\n",
       " 'often': ['Perez’s'],\n",
       " 'Perez’s': ['Achilles’', 'future'],\n",
       " 'Achilles’': ['heel.'],\n",
       " 'heel.': ['But'],\n",
       " 'But': ['up', 'Lewis', 'for'],\n",
       " 'up': ['against', 'to', 'in', 'a', 'at'],\n",
       " 'against': ['the'],\n",
       " 'juggernaut': ['that'],\n",
       " 'was': ['Max'],\n",
       " 'Max': ['Verstappen', 'Verstappen'],\n",
       " 'Verstappen': ['in', 'overjoyed', 'at'],\n",
       " 'RB19,': ['Perez'],\n",
       " 'still': ['secured'],\n",
       " 'secured': ['P2'],\n",
       " 'P2': ['in', 'in', 'in'],\n",
       " 'championship': ['–'],\n",
       " 'first': ['time', 'half'],\n",
       " 'time': ['Red'],\n",
       " 'had': ['finished'],\n",
       " 'finished': ['1-2'],\n",
       " '1-2': ['in'],\n",
       " 'drivers’.': ['Perez'],\n",
       " 'once': ['again'],\n",
       " 'again': ['driving'],\n",
       " 'driving': ['for'],\n",
       " 'With': ['Daniel'],\n",
       " 'Daniel': ['Ricciardo'],\n",
       " 'Ricciardo': ['back'],\n",
       " 'family': ['down'],\n",
       " 'down': ['at'],\n",
       " 'at': ['RB', 'Red', 'Suzuka', 'a', 'Mercedes', 'Suzuka', 'Red', 'Toro'],\n",
       " 'making': ['no'],\n",
       " 'no': ['secret'],\n",
       " 'secret': ['of'],\n",
       " 'ambition': ['to'],\n",
       " 'finish': ['his'],\n",
       " 'career': ['in', 'alongside'],\n",
       " 'Bull,': ['Liam', 'the'],\n",
       " 'Liam': ['Lawson'],\n",
       " 'Lawson': ['waiting'],\n",
       " 'waiting': ['in'],\n",
       " 'wings': ['and'],\n",
       " 'drivers’': ['market', 'championship.'],\n",
       " 'market': ['that', 'is', 'heats', 'at'],\n",
       " 'Carlos': ['Sainz'],\n",
       " 'Sainz': ['and', 'into', 'is'],\n",
       " 'Fernando': ['Alonso'],\n",
       " 'Alonso': ['as'],\n",
       " 'free': ['agents'],\n",
       " 'agents': ['for'],\n",
       " '2025,': ['there'],\n",
       " 'plenty': ['of'],\n",
       " 'chatter': ['about'],\n",
       " 'potential': ['moves'],\n",
       " 'moves': ['and'],\n",
       " 'particular': ['of'],\n",
       " 'late.': ['This'],\n",
       " 'This': ['year'],\n",
       " 'year': ['the', 'Sainz'],\n",
       " 'let': ['his'],\n",
       " 'performances': ['do'],\n",
       " 'do': ['the'],\n",
       " 'talking': ['and', 'to'],\n",
       " 'now': ['has'],\n",
       " 'three': ['second-place', 'podiums'],\n",
       " 'second-place': ['finishes'],\n",
       " 'finishes': ['from'],\n",
       " 'from': ['the', 'Melbourne,', 'his', '‘worst'],\n",
       " 'opening': ['four', 'four'],\n",
       " 'four': ['races', 'races'],\n",
       " 'races': ['to', 'of'],\n",
       " 'go': ['with'],\n",
       " 'fifth-place': ['from'],\n",
       " 'Melbourne,': ['and'],\n",
       " 'championship.': ['And'],\n",
       " 'And': ['Perez'],\n",
       " 'says': ['it', 'race'],\n",
       " 'won’t': ['be'],\n",
       " 'long': ['before'],\n",
       " 'revealed': ['what'],\n",
       " 'what': ['his', 'I’ve', 'I’m'],\n",
       " 'holds.': ['READ'],\n",
       " 'overjoyed': ['by'],\n",
       " 'by': ['victory'],\n",
       " 'victory': ['comeback'],\n",
       " 'comeback': ['at'],\n",
       " 'Suzuka': ['as', 'last'],\n",
       " 'race': ['‘couldn’t', 'in'],\n",
       " '‘couldn’t': ['have'],\n",
       " 'better’': ['“I'],\n",
       " '“I': ['am', 'believe'],\n",
       " 'am': ['pretty'],\n",
       " 'pretty': ['relaxed', 'much'],\n",
       " 'it,”': ['he'],\n",
       " 'told': ['Sky'],\n",
       " 'Sky': ['Sports'],\n",
       " 'Sports': ['F1'],\n",
       " 'after': ['the', 'P2'],\n",
       " 'Japan.': ['“My'],\n",
       " '“My': ['main'],\n",
       " 'main': ['focus'],\n",
       " 'focus': ['is'],\n",
       " 'whatever': ['comes'],\n",
       " 'comes': ['next,'],\n",
       " 'next,': ['I’m'],\n",
       " 'I’m': ['really', 'doing'],\n",
       " 'really': ['pleased', 'know'],\n",
       " 'pleased': ['with'],\n",
       " 'I’ve': ['done'],\n",
       " 'done': ['in'],\n",
       " 'sport': ['so'],\n",
       " 'far.': ['“I'],\n",
       " 'believe': ['it'],\n",
       " 'will': ['be'],\n",
       " 'matter': ['of'],\n",
       " 'time,': ['obviously'],\n",
       " 'obviously': ['the'],\n",
       " 'driver': ['market', 'market', 'who'],\n",
       " 'moving': ['and'],\n",
       " 'few': ['weeks'],\n",
       " 'weeks': ['are'],\n",
       " 'are': ['going', 'talking'],\n",
       " 'going': ['to'],\n",
       " 'lot': ['of'],\n",
       " 'movement': ['for'],\n",
       " 'sure,': ['so'],\n",
       " 'I': ['expect'],\n",
       " 'expect': ['within'],\n",
       " 'month': ['to'],\n",
       " 'know': ['what'],\n",
       " 'doing': ['next'],\n",
       " 'year.”': ['Perez'],\n",
       " 'podiums': ['from'],\n",
       " '': ['Often'],\n",
       " 'Often': ['the'],\n",
       " 'heats': ['up'],\n",
       " 'half': ['of'],\n",
       " 'culminating': ['in'],\n",
       " 'announcements': ['around'],\n",
       " 'around': ['the'],\n",
       " 'summer': ['break'],\n",
       " 'break': ['in'],\n",
       " 'August.': ['But'],\n",
       " 'Lewis': ['Hamilton’s'],\n",
       " 'Hamilton’s': ['shock'],\n",
       " 'shock': ['move'],\n",
       " 'move': ['to'],\n",
       " 'Ferrari': ['for'],\n",
       " '2025': ['ignited'],\n",
       " 'ignited': ['the'],\n",
       " 'much': ['earlier', 'everyone', 'performing'],\n",
       " 'earlier': ['stage'],\n",
       " 'stage': ['this'],\n",
       " 'year,': ['and'],\n",
       " 'only': ['freed'],\n",
       " 'freed': ['up'],\n",
       " 'coveted': ['seat'],\n",
       " 'Mercedes': ['but'],\n",
       " 'unleashed': ['an'],\n",
       " 'an': ['in-form'],\n",
       " 'in-form': ['Sainz'],\n",
       " 'into': ['the'],\n",
       " 'equation.': ['READ'],\n",
       " '‘good': ['momentum’'],\n",
       " 'momentum’': ['after'],\n",
       " 'Japan': ['amid'],\n",
       " 'amid': ['turnaround'],\n",
       " 'turnaround': ['from'],\n",
       " '‘worst': ['weekend’'],\n",
       " 'weekend’': ['at'],\n",
       " 'one': ['of'],\n",
       " 'number': ['of'],\n",
       " 'drivers': ['who'],\n",
       " 'who': ['could', 'wants'],\n",
       " 'could': ['conceivably'],\n",
       " 'conceivably': ['end'],\n",
       " 'end': ['up'],\n",
       " 'Spaniard': ['starting', 'has'],\n",
       " 'starting': ['his'],\n",
       " 'alongside': ['Max'],\n",
       " 'Toro': ['Rosso'],\n",
       " 'Rosso': ['as'],\n",
       " 'part': ['of'],\n",
       " 'family.': ['The'],\n",
       " 'admitted': ['his'],\n",
       " 'everyone': ['in'],\n",
       " 'paddock': ['as'],\n",
       " 'seeks': ['to'],\n",
       " 'secure': ['a'],\n",
       " '2025.': ['But'],\n",
       " 'now,': ['the'],\n",
       " '“Perez’s': ['to'],\n",
       " 'lose”': ['according'],\n",
       " 'according': ['to'],\n",
       " 'boss': ['Christian'],\n",
       " 'Christian': ['Horner,'],\n",
       " 'Horner,': ['with'],\n",
       " 'very': ['much'],\n",
       " 'performing': ['like'],\n",
       " 'like': ['a'],\n",
       " 'wants': ['to'],\n",
       " 'stay': ['in'],\n",
       " '1': ['next']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dictionary for Ali's routine, take a look at it\n",
    "perez_dict = markov_chain(perez_text)\n",
    "perez_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a function that generates sentences. It will take two things as inputs:\n",
    "* The dictionary you just created\n",
    "* The number of words you want generated\n",
    "\n",
    "Here are some examples of generated sentences:\n",
    "\n",
    ">'Shape right turn– I also takes so that she’s got women all know that snail-trail.'\n",
    "\n",
    ">'Optimum level of early retirement, and be sure all the following Tuesday… because it’s too.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(chain, count=8):\n",
    "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
    "       along with the number of words you would like to see in your generated sentence.'''\n",
    "\n",
    "    # Capitalize the first word\n",
    "    word1 = random.choice(list(chain.keys()))\n",
    "    sentence = word1.capitalize()\n",
    "\n",
    "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
    "    for i in range(count-1):\n",
    "        word2 = random.choice(chain[word1])\n",
    "        word1 = word2\n",
    "        sentence += ' ' + word2\n",
    "\n",
    "    # End it with a period\n",
    "    sentence += '.'\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japan. “My main focus is always the talking.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(perez_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment:\n",
    "1. Generate sentence for other comedians also.\n",
    "2. Try making the generate_sentence function better. Maybe allow it to end with a random punctuation mark or end whenever it gets to a word that already ends with a punctuation mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotoOnMercedes says: Remarked after what he felt went well. “The.\n",
      "AlonsoPraisesAMR says: Yeah, it and P10, and we still need.\n",
      "PerezOnHisFuture says: Pretty relaxed figure when asked about potential moves.\n",
      "SainzOnHisFuture says: Say is the Saudi Arabian Grand Prix “The.\n",
      "LeclercsPoorQualifying says: Advantage. While he looked to P4 drive in.\n",
      "HamiltonsCarIssues says: Terms of the Red Bull, and you’ve seen.\n",
      "TsunodaPoints says: Getaway in five-car pit stop “[I’m] relieved,” joked.\n"
     ]
    }
   ],
   "source": [
    "# Extract text for other comedians\n",
    "Article = [\"TotoOnMercedes\",\"AlonsoPraisesAMR\",\"PerezOnHisFuture\",\"SainzOnHisFuture\",\"LeclercsPoorQualifying\",\n",
    "           \"HamiltonsCarIssues\",\"TsunodaPoints\"] \n",
    "# Dictionary to store Markov chain for each comedian\n",
    "dicts = {}\n",
    "\n",
    "# Iterate over comedian names\n",
    "for name in Article:\n",
    "    article_text = data.transcript.loc[name]  # Assuming the data DataFrame contains transcripts for all comedians\n",
    "    dicts[name] = markov_chain(article_text)\n",
    "\n",
    "# Generate sentences for other comedians\n",
    "generated_sentences = {}\n",
    "\n",
    "for article, chain in dicts.items():\n",
    "    generated_sentences[article] = generate_sentence(chain)\n",
    "\n",
    "# Print generated sentences for each comedian\n",
    "for article, sentence in generated_sentences.items():\n",
    "    print(f\"{article} says: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 ignited the driver who wants to extend his performances do the driver who could.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "punct=['.','!','?']\n",
    "\n",
    "def generate_sentence(chain, max_words=15, end_with_punctuation=True):\n",
    "    '''Generate a sentence using a Markov chain dictionary.\n",
    "    \n",
    "    Args:\n",
    "    - chain: Markov chain dictionary\n",
    "    - max_words: Maximum number of words in the generated sentence\n",
    "    - end_with_punctuation: Whether to end the sentence with a punctuation mark\n",
    "    \n",
    "    Returns:\n",
    "    - A generated sentence\n",
    "    '''\n",
    "    \n",
    "    # Function to check if a word ends with punctuation\n",
    "    def ends_with_punctuation(word):\n",
    "        return word[-1] in punct\n",
    "    \n",
    "    # Reference to original function\n",
    "    def original_generate_sentence(chain, count=15):\n",
    "        '''Original version of generate_sentence function.'''\n",
    "        word1 = random.choice(list(chain.keys()))\n",
    "        sentence = word1.capitalize()\n",
    "        for i in range(count-1):\n",
    "            word2 = random.choice(chain[word1])\n",
    "            word1 = word2\n",
    "            sentence += ' ' + word2\n",
    "        sentence += '.'\n",
    "        return sentence\n",
    "    \n",
    "    # Capitalize the first word\n",
    "    word1 = random.choice(list(chain.keys()))\n",
    "    sentence = word1.capitalize()\n",
    "    \n",
    "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
    "    word_count = 1\n",
    "    while word_count < max_words:\n",
    "        word2 = random.choice(chain[word1])\n",
    "        sentence += ' ' + word2\n",
    "        word_count += 1\n",
    "        \n",
    "        # Check if the word ends with punctuation\n",
    "        if ends_with_punctuation(word2):\n",
    "            break\n",
    "        \n",
    "        word1 = word2\n",
    "    \n",
    "    # End it with a punctuation mark if specified\n",
    "    if end_with_punctuation:\n",
    "        if not ends_with_punctuation(sentence):\n",
    "            sentence += '.'\n",
    "        \n",
    "    return sentence.strip()\n",
    "\n",
    "# Example usage\n",
    "generated_sentence = generate_sentence(perez_dict)\n",
    "print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotoOnMercedes says: Monday MORNING DEBRIEF: Who nailed their performance later on, team mate Russell past Race day.\n",
      "AlonsoPraisesAMR says: Ultimately helped Alonso happy for differing tyre calls?\n",
      "PerezOnHisFuture says: Get outs for 2025, there has admitted his future.\n",
      "SainzOnHisFuture says: Best options for next year and Leclerc respond to “speed up” negotiations and Band of.\n",
      "LeclercsPoorQualifying says: Lap was overtaken by fans.\n",
      "HamiltonsCarIssues says: After the grid.  This feature is never what we need to provide consent to rue.\n",
      "TsunodaPoints says: “[i’m] relieved,” joked Tsunoda crosses the RB driver is not that and RB come Abu.\n"
     ]
    }
   ],
   "source": [
    "# Extract text for other comedians\n",
    "Article = [\"TotoOnMercedes\",\"AlonsoPraisesAMR\",\"PerezOnHisFuture\",\"SainzOnHisFuture\",\"LeclercsPoorQualifying\",\n",
    "           \"HamiltonsCarIssues\",\"TsunodaPoints\"] \n",
    "# Dictionary to store Markov chain for each comedian\n",
    "dicts = {}\n",
    "\n",
    "# Iterate over comedian names\n",
    "for name in Article:\n",
    "    article_text = data.transcript.loc[name]  # Assuming the data DataFrame contains transcripts for all comedians\n",
    "    dicts[name] = markov_chain(article_text)\n",
    "\n",
    "# Generate sentences for other comedians\n",
    "generated_sentences = {}\n",
    "\n",
    "for article, chain in dicts.items():\n",
    "    generated_sentences[article] = generate_sentence(chain)\n",
    "\n",
    "# Print generated sentences for each comedian\n",
    "for article, sentence in generated_sentences.items():\n",
    "    print(f\"{article} says: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
